\documentclass[../main/main.tex]{subfiles}

\begin{document}
\espacio

  %------------ TODO ------------%
  En este capítulo se muestra el marco teórico TODO.

  \section{Antecedentes}

  \subsection{Computación paralela}

  La computación paralela es una rama de la informática que se encarga del estudio de la ejecución de una tarea dividida en sub-procesos o varias tareas independientes de forma simultánea en forma de hilos de ejecución en un grupo de procesadores llamados también procesadores multinúcleo, que luego de realizar dichas tareas sincronizan sus resultados a fin de mantener la integridad de los datos.

  \begin{figure}[H]
    \centering
    \caption{Disposición de un microprocesadores multinúcleo}
    \input{\main/inc/cuadro_procesador}
    \caption*{\textbf{Fuente:} Elaboración propia}
  \end{figure}

  Los microprocesadores actuales contienen comúnmente dos tipos de núcleos, los núcleos físicos y los núcleos lógicos. Cada zócalo de una tarjeta madre contiene un microprocesador, este contiene uno o más núcleos físicos; un núcleo físico es aquel que se encuentra físicamente dentro del circuito integrado del microprocesador, mientras que un núcleo lógico es una división virtual en 2 o más partes de un núcleo físico. Las tareas son asignadas a los núcleos físicos; estas tareas pueden dividirse en tareas más pequeñas a fin de resolver un gran problema en partes pequeñas que al final serán unidas para generar la solución, estas partes pequeñas son llamadas ``hilos'' y son las que se ejecutan en los núcleo lógicos.

  \textit{Las técnicas principales para lograr estas mejoras de rendimiento (mayor frecuencia de reloj y arquitecturas cada vez más inteligentes y complejas) están golpeando la llamada ``Power Wall''. La industria informática ha aceptado que los futuros aumentos en rendimiento deben provenir en gran parte del incremento del número de procesadores (o núcleos) en una matriz, en vez de hacer más rápido un solo núcleo.} [\cite[p.~6]{report:parallel_computing_illinois}]

  El incremento de la frecuencia en los microprocesador acarrea consigo el consumo de energía y la disminución del espacio entre los transistores dentro de cada núcleo, lo que provoca un incremento considerable de la temperatura dentro del microprocesador; por tanto, para mantener el microprocesador en funcionamiento evitando su deterioro por las temperaturas elevadas es necesario buscar fuentes más óptimas de enfriado como los tubos de conducción de gas o líquido, que incrementan aún más el consumo de energía y que son costosos para una PC de escritorio.

  \begin{equation}
    T_m = T_a \cdot [( 1 - F_m ) + \frac{F_m}{A_m}]
    \label{ecuacion_amdahl}
  \end{equation}

  Donde:

  \begin{description}[noitemsep, nolistsep]
    \item[$F_m=$] Fracción de tiempo que el sistema utiliza el subsistema mejorado
    \item[$A_m=$] Factor de mejora que se ha introducido en el subsistema mejorado
    \item[$T_a=$] Tiempo de ejecución antiguo
    \item[$T_m=$] Tiempo de ejecución mejorado
  \end{description}

  Por tales motivos Gene Amdahl formuló la ecuación \ref{ecuacion_amdahl} que establece que:

  \textit{La mejora obtenida en el rendimiento de un sistema debido a la alteración de uno de sus componentes está limitada por la fracción de tiempo que se utiliza dicho componente}

  Despejando la ecuación \ref{ecuacion_amdahl} se obtiene la aceleración del programa completo una vez que se haya paralelizado uno o más algoritmos del programa.

  \begin{equation}
    A = \frac{1}{( 1 - F_m ) + \frac{F_m}{A_m}}
    \label{ecuacion_amdahl_aceleracion}
  \end{equation}

  Donde:

  \begin{description}[noitemsep, nolistsep]
    \item[$A=$] Aceleración o ganancia en velocidad conseguida en el sistema completo debido a la mejora de uno de sus subsistemas
    \item[$A_m=$] Factor de mejora que se ha introducido en el subsistema mejorado
    \item[$F_m=$] Fracción de tiempo que el sistema utiliza el subsistema mejorado
  \end{description}

  \begin{figure}[H]
    \centering
    \caption{Clúster de alto rendimiento}
    \includegraphics[width=10cm, keepaspectratio]{marco_teorico/cluster_alto_rendimiento.jpg}
    \caption*{\textbf{Fuente:} \cite[p.~2]{article:cluster_alto_rendimiento}}
  \end{figure}

  En base a este principio se desarrollaron tecnologías de matrices de núcleos de cómputo tomando como elementos principales a los procesadores existentes y acomodándolos de tal forma que se pueda administrar la ejecución de tareas en cada procesador de manera individual y la sincronización de resultados al final del proceso. Estos arreglos reciben el nombre de clústers. Los clústers de alto rendimiento son un tipo de clústers utilizados con el propósito de ejecutar tareas exhaustivas divididas en tareas pequeñas ejecutadas en cada computador de acuerdo a la gestión realizada por el llamado nodo maestro. [\cite{article:cluster_alto_rendimiento}]

  \begin{figure}[H]
    \centering
    \caption{Comparación de tiempos de proceso en múltiples CPUs}
    \includegraphics[width=15cm, keepaspectratio]{marco_teorico/resultado_cpu_cluster.png}
    \caption*{\textbf{Fuente:} \cite[p.~7]{article:cluster_alto_rendimiento}}
  \end{figure}

  \subsection{Unidad de procesamiento gráfico (GPU)}

  Esta unidad actúa como un co-procesador que se encarga de las operaciones matriciales o de coma flotante, por lo general los procesos gráficos de transformación o renderización son distribuidos a la o las GPUs desde el procesador central o CPU.

  Dado el estudio generado sobre las plataformas GPU, los fabricantes pusieron a disposición de los usuarios herramientas de desarrollo para utilizar las GPU como ayuda en cálculos de álgebra dispersa, tensores en dinámica de fluidos, minería de datos, inteligencia artificial, deep learning, etc, con lo cual la denominación de las GPU abiertas a otro tipo de uso más que el simple uso gráfico cambió a GPGPU\footnote{Unidad de Procesamiento Gráfico de Uso General (General Purpose Graphics Processing Unit)}.

  Estas tarjetas están desarrolladas en base al paralelismo de núcleos de frecuencia baja con un esquema de operaciones limitado.

  \begin{figure}[H]
    \centering
    \caption{Cantidad de núcleos en CPU vs GPU}
    \includegraphics[width=16cm, keepaspectratio]{marco_teorico/cpu_vs_gpu_cores.jpg}
    \caption*{\textbf{Fuente:} \cite{web:gpgpu}}
  \end{figure}

  El obstáculo principal para el desarrollo de aplicaciones orientadas hacia la GPU es que las arquitecturas de las tarjetas gráficas son demasiado variables, a pesar de la existencia de librerías o APIs genéricas como OpenGL, muchas funcionalidades dentro de los métodos o clases son variables entre fabricantes e incluso entre modelos de dispositivos de un mismo fabricante. Las librerías genéricas utilizan un núcleo basado en el esquema de Conductos de Renderización\footnote{Rendering Pipeline}, con los que se pueden tratar vectores, mapas de bits y elementos definidos pixel-pixel.

  Otro factor importante que impide hacer un uso adecuado de estos dispositivos es el límite físico con el que actualmente cuenta la conexión de memoria RAM de la GPU con el bus de la CPU para la transferencia de datos. Al cuarto trimestre de 2018 ya se cuenta con la tecnología GDDR6\footnote{Tasa Doble de transferencia de Datos  (Double Data Rate)} que ofrece un ancho de banda de hasta 16Gbps frente a los 10Gbps de su predecesor GDDR5X, cabe mencionar que se lograron estos anchos de banda gracias al cambio de modo half-duplex o transferencia en ambos sentidos pero solo uno a la vez, por el modo full-duplex que transfiere los datos en ambos sentidos al mismo tiempo.

  \begin{figure}[H]
    \centering
    \caption{Comparación de tecnologías GDDR6 vs GDDR5}
    \includegraphics[width=12cm, keepaspectratio]{marco_teorico/comparacion_gddr.png}
    \caption*{\textbf{Fuente:} \cite{web:comparacion_gddr}}
  \end{figure}

  Pero AMD ya se encuentra desarrollando tarjetas madres con conectores PCI-E\footnote{Componente Periférico de Interconexión Expresa (Peripheral Component Interconnect Express)} 5.0 que incrementarán la velocidad de transferencia hasta los 32Gbps que conjuntamente con el almacenamiento SSD\footnote{Solid State Drive} lograrán impulsar el desarrollo de aplicaciones de uso general en las GPUs.

  \begin{table}[H]
    \centering
    \caption{Comparación de tecnologías PCI-E}
    \input{\main/inc/tabla_comparativa_pcie}
    \caption*{\textbf{Fuente:} \cite{web:comparacion_pcie}}
  \end{table}

  \section{AES}

  El Estándar de Encriptación Avanzada fue de desarrollado mediante un concurso en 1997, por los criptógrafos Vincent Rijmen e Joan Daemen en el año 2001, como la sustitución al algoritmo DES\footnote{Estándar de Encriptación de Datos(Data Encryption Standard)} que había sido crackeado mediante la máquina DES Cracker construida por la ONG Electronic Frontier Foundation, con una inversión de 250 mil dólares. Este estándar fue aprobado y es utilizado por entes reguladores como la NSA\footnote{Agencia de Seguridad Nacional(National Security Agency)} y se estandariza mediante la norma ISO/IEC 18033 [\cite{standard:iso_18033}].

  El algoritmo AES Rijndael es un algoritmo de llave simétrica, lo cual indica que se utiliza una misma llave para cifrar y descifrar los mensajes en el lado del emisor y del receptor. Por tal razón, toda la seguridad recae en proteger la clave secreta, por tal razón el abanico de claves posibles debe ser de una cantidad tan grande que el intruso deba realizar pruebas, por inclusive años, para poder descifrar el mensaje. Para el caso de DES, la clave es de 56 bits por lo que la cantidad de claves será igual a: $2^{56} = 7.2 \times 10^{16}$ posibles claves; un computador actual puede lograr descifrar un mensaje mediante el cálculo de la llave secreta en un tiempo de tan solo segundos.

  \begin{table}[H]
    \centering
    \caption{Comparación de tecnologías PCI-E}
    \input{\main/inc/tabla_tamano_clave}
    \caption*{\textbf{Fuente:} \cite{web:tiempo_crack_aes}}
  \end{table}

  El algoritmo AES Rijndael trabaja con mensajes divididos en bloques de 128 bits y llaves de logitud de 128, 192 y 256 bits. Por lo tanto con una llave de 128 bits el atacante necesitaría generar: $2^{56} = 3.4 \times 10^{38}$ llaves, tarea que en la actualidad, aún con computadoras tan potentes, el trabajo tardaría millones de años.

  Suponiendo la super-computadora Summit de IBM [\cite{web:supercomputadora_summit_ibm}], designada para descifrar un mensaje, trabajando a $143.5PFlops$\footnote{Operaciones de Punto Flotante por Segundo(Floating point Operations Per Second)} o $143.5 \times 10^{15} Flops$ y sabiendo que la cantidad de segundos en un año es de: $365 x 24 x 60 x 60 = 31536000$. Se calcula la cantidad de años necesarios para crackear AES con una longitud de clave de 128 bits.


  \begin{equation}
    \begin{aligned}
    t &= \frac{3.4 \times 10^{38}}{143.5 \times 10^{15} x 31536000} \\
    t &= \frac{23.69 \times 10^{15}}{315.36} \\
    t &= 75.13 \times 10^{12} a\tilde{n}os
    \end{aligned}
  \end{equation}

  Es decir, con la última tecnología disponible actualmente se tomaría un tiempo de 75.13 billones de años en generar las llaves secretas necesarias para descifrar un mensaje. Suponiendo que solo fuese necesario generar la mitad de las llaves para encontrar la correcta, el proceso tardaría mas de 32 billones de años. Por lo tanto una llave secreta de 128 bits utilizada para cifrar un mensaje con el algoritmo AES Rijndael es suficiente seguridad para la actualidad y para unos años más en el futuro.

  \subsection{Etapas del cifrado AES Rijndael}



  \begin{figure}[H]
    \centering
    \caption{Algoritmo AES Rijndael}
    \input{\main/inc/cuadro_algoritmo_aes}
    \caption*{\textbf{Fuente:} Elaboración propia}
  \end{figure}


\end{document}