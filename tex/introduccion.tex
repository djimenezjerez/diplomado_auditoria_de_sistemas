% !TeX root = ../main/main.tex
\documentclass[../main/main.tex]{subfiles}

\begin{document}
\espacio

  En este capítulo se muestran: el panorama general del problema que se analizará, la importancia teórica y práctica del resultado del análisis.

  \section{Aspectos generales}

  La computación en la nube ha cambiado el paradigma con el que se brindan la mayoría de los servicios web en la actualidad. Alrededor del año de 1990, los servidores eran computadoras con características no muy distintas a las computadoras personales, la diferencia era que esos servidores se enfocaban únicamente en brindar un servicio en específico que los equipos clientes podían consultar. Con el paso del tiempo esta forma de brindar servicios cambió y se comenzaron a fabricar equipos servidores con características mucho mayores que las de un equipo de uso personal ya que los servicios precisaban de otros servicios como las bases de datos, en ese momento la web estática se convirtió en web dinámica y los datos se convirtieron en un valor comercial. Pero llegó otro instante en el que los servicios ya no solo ofrecian datos sino que se convirtieron en aplicaciones, soluciones que podían procesar datos de entrada y devolver cálculos bastante extensos con datos compartidos entre una gran cantidad de servicios interconectados entre sí, y con ello surgión finalmente la computación en la nube.

  Aún con la gran capacidad de procesamiento de los equipos servidores contravino el nuevo paradigma que distribuye dicha capacidad ya que la mayoría de los servicios tiene tiempos muertos de procesador en los cuales otra aplicación podría hacer uso del mismo y de esta forma incrementar la eficiencia de los servicios. Por ello las aplicaciones se distribuyeron aún más y se comenzaron a empaquetar en máquinas virtuales a nivel baremetal, pero aún quedaba el problema de la complejidad de despliegue de servicios, la interconexión de las máquinas virtuales y el trabajo duro en cuanto a la configuración de las aplicaciones mismas. Un ejemplo claro de este tipo de soluciones es Hyper-V y también KVM.

  Los desarrolladores de sistemas se especializaron en un amplio número de áreas que componen a un mismo software; es decir que, ya no solo se necesitaban desarrolladores de aplicaciones fullstack, sino que ahora son necesarios programadores backend, frontend, desarrolladores de experiencia de usuario, de interfaz de usuario, testers de la calidad del software, etc. Con lo cual fué necesario aplicar un estandar para el desarrollo de software como SCRUM, Agile, Kanban, etc, que llegan a tener dos parámetros en común, estos son: Integración Contínua (CI)\footnote{Continuous Integration} y Despliegue Contínuo (CD)\footnote{Continuous Deployment}.

  En respuesta a ello surgió la idea de un nuevo tipo de virtualización conocida como virtualización ligera o de contenedores, una de las primeras soluciones llegó a ser LVM\footnote{Logical Volume Management} que funciona básicamente generando un volumen para una aplicación específica que se basa en el kernel del sistema operativo anfitrión, posteriormente se generaron otras soluciones, una de las más populares al momento de este análisis es Docker\footnote{\href{https://www.docker.com/}}. Cualquiera de las soluciones de virtualización ligera se basa en el mismo principio, una imagen que contiene una base de la aplicación que se desea desplegar, en la cual se inserta un volumen con el código fuente a ejecutar en el caso de las aplicaciones o un volumen preparado con la estructura en el caso de bases de datos, ambos con un entorno específico de ejecución y nombres de espacio diferenciados para aislar cada contenedor en su propio ambiente de trabajo.

  La solución como tal es una idea bastante potente ya que las ``recetas'' utilizadas para el despliegue de las aplicaciones es bastante flexible y además orquestable para rearmar una cantidad grande de aplicaciones interconectadas mediante redes SDN\footnote{Software Defined Network}. Pero el problema que surgió a medida que la popularidad de estas soluciones fue en incremento es la seguridad en los contenedores.

  Como se mencionó anteriormente, los contenedores se basan en imágenes prediseñadas que vienen instaladas con las configuraciones por defecto. El análisis que se muestra en este documento demuestra que un número razonable de imágenes provistas oficialmente para la plataforma de virtualización de contenedores Docker cuenta con las configuraciones por defecto, por lo que se implica que las recetas usadas para el despliegue de los contenedores deben contemplar la seguridad del contenedor como tal, además de la seguridad en el acceso a la aplicación del entorno propio de la imagen.

  \section{Importancia teórica y práctica}

  \begin{table}
    \centering
    \caption{Aplicaciones del algoritmo AES}
    \input{\main/inc/tabla_uso_aes}
    \caption*{\textbf{Fuente:} \href{https://en.wikipedia.org/wiki/AES_implementations}{Implementaciones AES, Aplicaciones, Wikipedia}}
    \label{tabla_uso_aes}
  \end{table}

  El Estándar de Encriptación Avanzada (AES Rijndael) es utilizado en muchas aplicaciones actuales debido a su característica de patrón abierto para uso público y privado en aplicaciones personales y empresariales.

  Cualquier incremento en la velocidad de ejecución de este algoritmo es de gran importancia práctica, ya que, como se muestra en el cuadro \ref{tabla_uso_aes}, los protocolos SSL y TLS trabajan con encriptación AES Rijndael, y es sabido que una gran parte de los servicios brindados en VPN y HTTPS para red local y/o internet transmiten grandes bloques de información encriptada, por lo cual la ejecución de este proceso debe ser lo más rápida posible a fin de evitar latencia en las comunicaciones.

  Por otra parte, en lo que respecta a la teoría de hilos y paralelismo de ejecución de procesos, la investigación del uso de tarjetas gráficas como unidades de procesamiento de datos es todavía un área joven sobre la cual se está comenzando a investigar, con el desarrollo de la tecnología TITAN de NVidia \footnote{\href{https://www.nvidia.com/en-us/titan/titan-rtx/}{Tecnología NVidia Titan RTX}}, misma que pone a disposición mallas de miles de procesadores Tensor y CUDA; dichos procesadores son núcleos de uso específico y no cuentan con las capacidades de los procesadores de uso general.

  Entre los aspectos que caracterizan estas tecnologías de procesamiento están principalmente las operaciones matriciales, las operaciones de bucle independiente y las operaciones de transformación de datos.
\end{document}